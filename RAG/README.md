#RAG System with Local Models Using Ollama
Project for building a Retrieval-Augmented Generation (RAG) ,model capable of handling multiple PDF documents from different domains.
ðŸ™‚CONCEPTS INVOLVED
ïƒ˜	RAG System: A type of question-answering system that combines retrieval and generation capabilities.
ïƒ˜	DocumentProcessor: A class responsible for processing documents, including text splitting and embedding generation.
ïƒ˜	VectorStore: A data structure used to store and query document embeddings.
ïƒ˜	LLM (Ollama): A large language model used for generating answers to user queries.
ïƒ˜	Streamlit: A library used to build the user interface for the RAG system.
ïƒ˜	PyPDFLoader: A library used to load PDF documents.
ïƒ˜	RecursiveCharacterTextSplitter: A text splitter used to split documents into smaller chunks.
ïƒ˜	HuggingFaceEmbeddings: A library used to generate embeddings for document chunks.
ïƒ˜	FAISS: A library used to implement the VectorStore.
ïƒ˜	ChatPromptTemplate: A library used to create a prompt template for the LLM.
