# RAG System with Local Models Using Ollama

Project for building a Retrieval-Augmented Generation (RAG) model capable of handling multiple PDF documents from different domains. ðŸ˜Š

## Concepts Involved

- **RAG System**: A type of question-answering system that combines retrieval and generation capabilities.
- **DocumentProcessor**: A class responsible for processing documents, including text splitting and embedding generation.
- **VectorStore**: A data structure used to store and query document embeddings.
- **LLM (Ollama)**: A large language model used for generating answers to user queries.
- **Streamlit**: A library used to build the user interface for the RAG system.
- **PyPDFLoader**: A library used to load PDF documents.
- **RecursiveCharacterTextSplitter**: A text splitter used to split documents into smaller chunks.
- **HuggingFaceEmbeddings**: A library used to generate embeddings for document chunks.
- **FAISS**: A library used to implement the VectorStore.
- **ChatPromptTemplate**: A library used to create a prompt template for the LLM.


## Getting Started
### Prerequisites
Python Version 3.11.


### Installation
Step-by-step instructions on how to install and set up your project.
